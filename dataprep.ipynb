{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import matplotlib.pyplot as plt\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=\"hand_landmarker.task\")\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options,\n",
    "                                     num_hands=2)\n",
    "detector = vision.HandLandmarker.create_from_options(options)\n",
    "\n",
    "def print_landmarks_coordinates(hand_landmarks_list, handedness_list):\n",
    "    # Dictionary of landmark names\n",
    "    right_landmarks = np.zeros((2,21,3))\n",
    "\n",
    "    \n",
    "    for hand_idx, hand_landmarks in enumerate(hand_landmarks_list):\n",
    "        if handedness_list[hand_idx][0].category_name == \"Right\":\n",
    "            hand_array = [[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks]\n",
    "            landmarks_array = np.array(hand_array)\n",
    "            right_landmarks[0]=landmarks_array\n",
    "        if handedness_list[hand_idx][0].category_name == \"Left\":\n",
    "            hand_array = [[landmark.x, landmark.y, landmark.z] for landmark in hand_landmarks]\n",
    "            landmarks_array = np.array(hand_array)\n",
    "            right_landmarks[1]=landmarks_array\n",
    "\n",
    "    return right_landmarks\n",
    "\n",
    "def process_image(frame):\n",
    "    # print(\"Processing for files \"+frame)\n",
    "    frame = cv2.imread(frame)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create MediaPipe image from the RGB frame\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    \n",
    "    # Detect hand landmarks\n",
    "    detection_result = detector.detect(mp_image)\n",
    "\n",
    "    # Print coordinates\n",
    "    coordinates = print_landmarks_coordinates(detection_result.hand_landmarks, detection_result.handedness)\n",
    "\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24971/24971 [21:45<00:00, 19.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRecord and label mapping saved. Classes: {0: 'apa', 1: 'bagus', 2: 'berapa', 3: 'bicara', 4: 'bisa', 5: 'buruk', 6: 'iya', 7: 'kapan', 8: 'kasih', 9: 'kau', 10: 'kita', 11: 'maaf', 12: 'perlu', 13: 'saya', 14: 'sedih', 15: 'senang', 16: 'terima', 17: 'tidak', 18: 'tidak_ada', 19: 'tolong', 20: 'tunggu'}\n",
      "Sample records:\n",
      "Sample 1: data shape (2, 21, 3), label shape (21,), label [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Sample 2: data shape (2, 21, 3), label shape (21,), label [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Sample 3: data shape (2, 21, 3), label shape (21,), label [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Batch data shape: (16, 2, 21, 3)\n",
      "Batch label shape: (16, 21)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "\n",
    "\n",
    "def print_landmarks_coordinates(hand_landmarks_list, handedness_list):\n",
    "    right_landmarks = np.zeros((2,21,3), dtype=np.float32)\n",
    "    for hand_idx, hand_landmarks in enumerate(hand_landmarks_list):\n",
    "        if handedness_list[hand_idx][0].category_name == \"Right\":\n",
    "            hand_array = [[landmark.x, landmark.y, 0] for landmark in hand_landmarks]\n",
    "            landmarks_array = np.array(hand_array, dtype=np.float32)\n",
    "            right_landmarks[0] = landmarks_array\n",
    "        if handedness_list[hand_idx][0].category_name == \"Left\":\n",
    "            hand_array = [[landmark.x, landmark.y, 0] for landmark in hand_landmarks]\n",
    "            landmarks_array = np.array(hand_array, dtype=np.float32)\n",
    "            right_landmarks[1] = landmarks_array\n",
    "    return right_landmarks\n",
    "\n",
    "def process_image(image_path):\n",
    "    # print(\"Processing for files \"+frame)\n",
    "    frame = cv2.imread(image_path)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create MediaPipe image from the RGB frame\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "    \n",
    "    # Detect hand landmarks\n",
    "    detection_result = detector.detect(mp_image)\n",
    "\n",
    "    # Print coordinates\n",
    "    coordinates = print_landmarks_coordinates(detection_result.hand_landmarks, detection_result.handedness)\n",
    "    assert coordinates.shape == (2,21,3), f\"BAD SHAPE: {coordinates.shape} for {image_path}\"\n",
    "    assert coordinates.dtype == np.float32, f\"BAD DTYPE: {coordinates.dtype} for {image_path}\"\n",
    "    return coordinates\n",
    "\n",
    "# --- Paths ---\n",
    "WORKSPACE_PATH = \"E:/Folder_mata_kuliah/Semester_7/PRA TA/Python prep/workspace_jauh\"\n",
    "DATASET_PATH = os.path.join(WORKSPACE_PATH, \"Dataset\")\n",
    "OUTPUT_TFRECORD = os.path.join(WORKSPACE_PATH, \"dataset_without_mirror_without_z_also_21class.tfrecords\")\n",
    "-\n",
    "def create_tf_example(processed_data, label_index):\n",
    "    feature = {\n",
    "        'coordinates': tf.train.Feature(float_list=tf.train.FloatList(value=processed_data.flatten())),\n",
    "        'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label_index])),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "def create_tfrecord():\n",
    "\n",
    "    label_folders = [f for f in os.listdir(DATASET_PATH) if os.path.isdir(os.path.join(DATASET_PATH, f))]\n",
    "    label_folders.sort()\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(label_folders)\n",
    "\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for label in label_folders:\n",
    "        label_path = os.path.join(DATASET_PATH, label)\n",
    "        image_files = glob.glob(os.path.join(label_path, \"*.jpg\"))\n",
    "        image_paths.extend(image_files)\n",
    "        labels.extend([label] * len(image_files))\n",
    "\n",
    "    encoded_labels = label_encoder.transform(labels)\n",
    "\n",
    "    with tf.io.TFRecordWriter(OUTPUT_TFRECORD) as writer:\n",
    "        for image_path, label_index in tqdm(zip(image_paths, encoded_labels), total=len(image_paths)):\n",
    "            processed_data = process_image(image_path)\n",
    "            # if np.all(processed_data == 0):  # Skip if all values are zero\n",
    "            #     continue\n",
    "            example = create_tf_example(processed_data, label_index)\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "    label_mapping = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "    with open(os.path.join(WORKSPACE_PATH, \"dataset_labels.txt\"), \"w\") as f:\n",
    "        for idx, name in label_mapping.items():\n",
    "            f.write(f\"{idx}: {name}\\n\")\n",
    "    print(f\"TFRecord and label mapping saved. Classes: {label_mapping}\")\n",
    "\n",
    "def read_tfrecord(num_classes):\n",
    "    feature_description = {\n",
    "        'coordinates': tf.io.FixedLenFeature([2*21*3], tf.float32),  # Flattened 2x21x3 tensor\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    def _parse_function(example_proto):\n",
    "        parsed = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        coordinates = tf.reshape(parsed['coordinates'], (2,21,3))\n",
    "        label = tf.one_hot(parsed['label'], depth=num_classes)\n",
    "        return coordinates, label\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(OUTPUT_TFRECORD).map(_parse_function)\n",
    "    print(\"Sample records:\")\n",
    "    for i, (data, label) in enumerate(dataset.take(3)):\n",
    "        print(f\"Sample {i+1}: data shape {data.shape}, label shape {label.shape}, label {label.numpy()}\")\n",
    "    return dataset\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_tfrecord()\n",
    "\n",
    "    with open(os.path.join(WORKSPACE_PATH, \"dataset_labels.txt\")) as f:\n",
    "        lines = f.readlines()\n",
    "    num_classes = len(lines)\n",
    "\n",
    "    parsed_dataset = read_tfrecord(num_classes)\n",
    "\n",
    "    train_dataset = parsed_dataset.shuffle(100).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "    for data_batch, label_batch in train_dataset.take(1):\n",
    "        print(\"Batch data shape:\", data_batch.shape)\n",
    "        print(\"Batch label shape:\", label_batch.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
